\section{Experiments} \label{sec:experiments}

To test the approximate counting in ASP, we extend \xorro{} with the algorithms described in the section above.
For now, we focus only on the quality of the counting, leaving the scalability and performance for further work.
%
To test the quality of the counting,
we generated ten random instances from different ASP problem classes such as Graph Coloring, Minimal Vertex Cover, Schur Decision Problem, Hamiltonian Path, Subset Minimal Independent Vertex, and an encoding for projected model counting on 2-QBFs~\cite{KleineBuningLettman99}.~\footnote{The encodings and instances can be found in: \url{https://tinyurl.com/approx-asp}}
Also, to track the counting, we cared that these instances were ``easy to solve'' for \clasp{},
meaning that \clasp{} must enumerate all answer sets within 600 seconds timeout (without printing).

To get the feeling for our initial counting experiments, we fixed the tolerance and the confidence values to 0.8, and 0.2 respectively, as shown in~\cite{ChakrabortyMV13}.
In other words, we kept the same pivot value seeking for a "small" cell and the number of iterations fixed, as shown in lines 3 and 8 from Algorithm 1, respectively.
As part of the setup of the experiments and for comparisson, we asked \xorro{} to estimate the count also by calcuating the median from the original ApproxMC Algorithm in~\cite{ChakrabortyMV13}.

The experiments were run sequentially under Linux on a 16 GB memory with a 2.60 GHz Dual-Core Intel Core i7 processor laptop.
Each benchmark instance (in smodels output format, generated offline with \gringo{}) was five times and restricted to 600 seconds.
As shown in Algorithm 1, a run is finished with one of three possible situations, either \xorro{} returns the approximate answer sets count or unsatisfiability, or without the count due to time exhaustion.

Our experiments' results are summarized in Tables 1-TBD listing for each problem class instances, the number of answer sets in the first two columns.
The remainder of the table is divided into the best and worst runs from the five. 
%
For both cases, we list the median and the mean counts, each with a quality factor (Q) estimating the closeness to the total number of answer sets.
The last row of each table displays the average Q for each count.

\begin{table*}[t]
  \centering
  \input{tables/graph_color}
  \caption{Approximate answer set count over random instances of the Graph Coloring problem.}\label{table:graph_color}
\end{table*}


\begin{table*}[t]
  \centering
  \input{tables/vertex_cover}
  \caption{Approximate answer set count over random instances of the Minimum Vertex Cover problem.}\label{table:min_vertex_cover}
\end{table*}

\begin{table*}[t]
  \centering
  \input{tables/schur}
  \caption{Approximate answer set count over random instances of the Schur decision problem.}\label{table:schur}
\end{table*}


\begin{table*}[t]
  \centering
  \input{tables/hampath}
  \caption{Approximate answer set count over random instances of the Hamiltonian Path problem.}\label{table:hampath}
\end{table*}


% comment results


The large deviations between the best and the worst cases correspond to one of two possible scenarios.
%
If the count is under approximating,
it means the partition was not well distributed, and some clusters had too few or too many answer sets. 
%
On the opposite case, where there is an over-approximation count,
our set of \XOR{}s contains linear combinations or linearly dependent equations,
meaning that the partitioning is not performed concerning the number of \XOR{}s.
% 
For instance, the conjunction of the \XOR{} constraints $a \xor \top \land b \xor \top \land a \xor b \xor \top$ can be equivalently reduced to $a \xor \top \land b \xor \top$. 
%
Back to our example in Section~\ref{sec:parity}, instead of counting $|S|$ $\cdot 2^5$ being $S=2$,
one linear combination causes the double of answer sets from the resulting cluster, so for this case, $S=4$, and the approximate count is 1024 instead of 64. 



As we mentioned above, the performance was not examined for this paper,
meaning that it is worth considering for further experiments by testing all the different approaches from \xorro{}.
For the experiments above, we ran \xorro{} with the lazy counting approach,
which got the highest overall performance score from all the six implementations.
However, the random parity constraints generated during each counting iteration were quite small,
meaning that other approaches would benefit more for these \XOR{}s densities, like the Unit Propagation approach~\cite{DBLP:conf/lpnmr/EverardoJKS19}.